{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d01a07f-e289-418c-a09e-207e36dc4d07",
   "metadata": {},
   "source": [
    "# **Step 01: Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88744cb9-7bbd-44fe-8464-248a50942863",
   "metadata": {},
   "source": [
    "# A. Import Libraries and Set Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae79b9-ef5c-4fa3-9b2a-27604b5a962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/ksnugroho/bncc-ai-azure/raw/refs/heads/main/leaf-disease-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"leaf-disease-dataset.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"leaf-disease-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d7684-bc73-43ca-9d4c-e22f429d7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c17693",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install torchvista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1365bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "\n",
    "# PyTorch core modules\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# Evaluation modules\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvista import trace_model\n",
    "\n",
    "# Set a deterministic seed for reproducible results\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Select GPU if available, otherwise CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# Path to the dataset directory\n",
    "DATA_PATH = Path(\"leaf-disease-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576f5857-b41e-46b4-a7c8-e7290e042e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n",
    "print(\"pandas:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd169a-9081-4f77-ae0f-b1fdc19e690c",
   "metadata": {},
   "source": [
    "# B. Prepare Dataset, Transforms, and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ffd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image preprocessing pipeline (resize, convert to tensor, normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],       # Standard ImageNet mean\n",
    "        std=[0.229, 0.224, 0.225]         # Standard ImageNet std\n",
    "    )\n",
    "])\n",
    "\n",
    "# Load dataset using folder structure (one folder per class)\n",
    "full_dataset = datasets.ImageFolder(str(DATA_PATH), transform=transform)\n",
    "\n",
    "# Extract class labels\n",
    "targets = [y for _, y in full_dataset.samples]\n",
    "CLASS_NAMES = full_dataset.classes\n",
    "print(\"Classes found:\", CLASS_NAMES)\n",
    "\n",
    "# Create stratified train/validation split to preserve class ratio\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(targets)),\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=targets\n",
    ")\n",
    "\n",
    "# Wrap indices into Subset objects\n",
    "train_ds = Subset(full_dataset, train_idx)\n",
    "val_ds   = Subset(full_dataset, val_idx)\n",
    "\n",
    "# Create DataLoaders for efficient batching\n",
    "BATCH_SIZE = 16\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Total samples: {len(full_dataset)}  Train: {len(train_ds)}  Val: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4700aa7-8ec6-4237-a9a5-ea357e28aa2f",
   "metadata": {},
   "source": [
    "# C. Initialize Model and Trace Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd85fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More vision architectures in PyTorch (CNNs, Vision Transformers, and hybrids):\n",
    "# https://docs.pytorch.org/vision/main/models.html\n",
    "\n",
    "# Example model: EfficientNet (CNN-based)\n",
    "# Original paper: \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\"\n",
    "# https://arxiv.org/abs/1905.11946\n",
    "\n",
    "# Load pre-trained EfficientNet-B0 model with ImageNet weights:\n",
    "# https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b0.html#torchvision.models.efficientnet_b0\n",
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "\n",
    "# Replace final classification layer to match the number of target classes\n",
    "model.classifier = nn.Linear(model.classifier[1].in_features, len(CLASS_NAMES))\n",
    "\n",
    "model = model.to(DEVICE)  # Move model to GPU/CPU device\n",
    "model.eval()              # Set model to evaluation mode for tracing\n",
    "\n",
    "# Create a dummy input tensor for model tracing/visualization\n",
    "example_input = torch.randn(1, 3, 244, 244).to(DEVICE)\n",
    "\n",
    "# Generate model trace visualization\n",
    "trace_model(model, example_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651891fa-6b3f-413d-b7ea-b0178ad2fc0d",
   "metadata": {},
   "source": [
    "# D. Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d0d2e-e576-4bd8-be69-a02e827d3e6e",
   "metadata": {},
   "source": [
    "## Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b210ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20797a-045c-4e45-8784-98f592a242f1",
   "metadata": {},
   "source": [
    "## Define Training Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_function, device):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    preds_all, labels_all = [], []\n",
    "    start_time = perf_counter()  # Measure epoch duration\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()                     # Clear previous gradients\n",
    "        output = model(x)                         # Forward pass\n",
    "        batch_loss = loss_function(output, y)     # Compute loss\n",
    "        batch_loss.backward()                     # Backpropagation\n",
    "        optimizer.step()                          # Update model parameters\n",
    "\n",
    "        epoch_loss += batch_loss.item() * x.size(0)          # Accumulate batch loss\n",
    "\n",
    "        preds = output.argmax(dim=1).detach().cpu().numpy()  # Predictions\n",
    "        labels = y.detach().cpu().numpy()                    # Ground truth\n",
    "        preds_all.append(preds)\n",
    "        labels_all.append(labels)\n",
    "\n",
    "    end_time = perf_counter() - start_time\n",
    " \n",
    "    # Aggregate predictions and compute metrics\n",
    "    y_pred = np.concatenate(preds_all)\n",
    "    y_true = np.concatenate(labels_all)\n",
    "    n = len(y_true)\n",
    "\n",
    "    avg_loss = epoch_loss / n\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    return {\n",
    "        \"loss\": avg_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"time_s\": end_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5464da2-ed2b-469f-ade8-76f31cdee513",
   "metadata": {},
   "source": [
    "## Define Validation Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c568ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, loss_function, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    preds_all, labels_all = [], []\n",
    "    start_time = perf_counter()  # Measure validation duration\n",
    "\n",
    "    with torch.no_grad():        # Disable gradient computation\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            output = model(x)                           # Forward pass only\n",
    "            batch_loss = loss_function(output, y)       # Compute validation loss\n",
    "            epoch_loss += batch_loss.item() * x.size(0)\n",
    "\n",
    "            preds = output.argmax(dim=1).cpu().numpy()  # Predictions\n",
    "            labels = y.cpu().numpy()                    # Ground truth\n",
    "            preds_all.append(preds)\n",
    "            labels_all.append(labels)\n",
    "\n",
    "    end_time = perf_counter() - start_time\n",
    "\n",
    "    # Aggregate predictions and compute metrics\n",
    "    y_pred = np.concatenate(preds_all)\n",
    "    y_true = np.concatenate(labels_all)\n",
    "    n = len(y_true)\n",
    "\n",
    "    avg_loss = epoch_loss / n if n > 0 else 0.0\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    return {\n",
    "        \"loss\": avg_loss,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"time_s\": end_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404b70c-8fff-4f45-be96-30f856e59c33",
   "metadata": {},
   "source": [
    "# E. Run Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 3\n",
    "history = {\"train\": [], \"val\": []}   # Store metrics for monitoring\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    # Perform one epoch of training and validation\n",
    "    train_stats = train(model, train_dl, OPTIMIZER, LOSS_FUNCTION, DEVICE)\n",
    "    val_stats   = validate(model, val_dl, LOSS_FUNCTION, DEVICE)\n",
    "\n",
    "    # Save metrics\n",
    "    history[\"train\"].append(train_stats)\n",
    "    history[\"val\"].append(val_stats)\n",
    "\n",
    "    # Print progress summary for the current epoch\n",
    "    print(f\"Epoch {ep} â€” Train loss: {train_stats['loss']:.4f}  \"\n",
    "          f\"acc: {train_stats['accuracy']:.4f}  f1: {train_stats['f1_macro']:.4f}  \"\n",
    "          f\"time: {train_stats['time_s']:.1f}s\")\n",
    "    \n",
    "    print(f\"           Val   loss: {val_stats['loss']:.4f}  \"\n",
    "          f\"acc: {val_stats['accuracy']:.4f}  f1: {val_stats['f1_macro']:.4f}  \"\n",
    "          f\"time: {val_stats['time_s']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a85fa-d0c6-49e1-8fed-81da05481ca8",
   "metadata": {},
   "source": [
    "## Plot Training and Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [h['loss'] for h in history['train']]\n",
    "val_loss = [h['loss'] for h in history['val']]\n",
    "\n",
    "train_acc = [h['accuracy'] for h in history['train']]\n",
    "val_acc = [h['accuracy'] for h in history['val']]\n",
    "\n",
    "epochs_range = range(1, len(train_loss) + 1)\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, train_loss, label=\"Training Loss\") \n",
    "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range, train_acc, label=\"Training Accuracy\") \n",
    "plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497b246d-4985-47dd-8917-858851f6aa88",
   "metadata": {},
   "source": [
    "# F. Evaluation\n",
    "Read more: https://ksnugroho.medium.com/confusion-matrix-untuk-evaluasi-model-pada-unsupervised-machine-learning-bc4b1ae9ae3f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711794bb-8c96-4e13-8c2c-3a4d3cc83acf",
   "metadata": {},
   "source": [
    "## Define Prediction Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e937164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_and_trues(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    labels_all, preds_all, probs_all = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            \n",
    "            probs = torch.softmax(output, dim=1)[:, 1].cpu().numpy() \n",
    "            preds = output.argmax(dim=1).cpu().numpy()\n",
    "            \n",
    "            labels_all.append(y.cpu().numpy())\n",
    "            preds_all.append(preds)\n",
    "            probs_all.append(probs)\n",
    "            \n",
    "    y_true = np.concatenate(labels_all)\n",
    "    y_pred = np.concatenate(preds_all)\n",
    "    y_score = np.concatenate(probs_all) \n",
    "    \n",
    "    return y_true, y_pred, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, y_score = get_preds_and_trues(model, val_dl, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb647b-b958-4668-a9fd-d1caf9ed8a0a",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ceb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, digits=4, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884330d0-b5d0-4fd1-acbb-15e1818f6c53",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(y_true, y_pred),\n",
    "    display_labels=CLASS_NAMES\n",
    ")\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues) # Menggunakan skema warna Biru\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920621a-71e4-42e6-a044-2ee575d8ec6e",
   "metadata": {},
   "source": [
    "## Plot ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7579ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(y_true, y_score)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b747c7-cd70-45e9-821d-3358e4f3857a",
   "metadata": {},
   "source": [
    "# G. Save Trained Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e2221-5157-413a-9d50-15a7be83d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(), \n",
    "    \"classes\": CLASS_NAMES\n",
    "}, \"artifacts/model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - Pytorch and Tensorflow",
   "language": "python",
   "name": "python38-azureml-pt-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
